{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning with Python\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "path = r'C:\\Users\\LLerma\\Documents\\GitHub\\Learning\\Datasets'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basics of DL and NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The layer at the left is \"Input Layer\" \\\n",
    "The layer at the right is \"Output Layer\"\\\n",
    "Tha layers in the middle are \"Hidden Layers\"\n",
    "\n",
    "Each node in the hidden layer, represents an aggregation of information from our input data, and each node adds to the model's ability to capture interactions. The more nodes we have, the more interactions we capture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weights, are the parameters we train when we fit a NN to the data. In this case, we multiply each input variable by the corresponding weights and then sum (dot product); and so on with each layer until the Output node.\n",
    "\n",
    "1. Multiply - add process\n",
    "2. Dot product\n",
    "3. Forward propagation for one data point at a time\n",
    "4. Output is the prediction for that data point\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "input_data = np.array([2, 3])\n",
    "weights = { 'node_0': np.array([1, 1]),\n",
    "            'node_1': np.array([-1, 1]),\n",
    "            'output': np.array([2, -1])}\n",
    "node_0_value = (input_data * weights['node_0']).sum()\n",
    "node_1_value = (input_data * weights['node_1']).sum()\n",
    "\n",
    "hidden_layer_values = np.array([node_0_value,node_1_value])\n",
    "\n",
    "output = (hidden_layer_values * weights['output']).sum() #Dot product\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some examples of activation functions, are:\n",
    "\n",
    "* Sigmoid\n",
    "* Tanh\n",
    "* ReLU (Rectified Linear Activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2382242525694254\n"
     ]
    }
   ],
   "source": [
    "input_data = np.array([2, 3])\n",
    "weights = { 'node_0': np.array([1, 1]),\n",
    "            'node_1': np.array([-1, 1]),\n",
    "            'output': np.array([2, -1])}\n",
    "node_0_input = (input_data * weights['node_0']).sum()\n",
    "node_0_output = np.tanh(node_0_input)\n",
    "\n",
    "node_1_input = (input_data * weights['node_1']).sum()\n",
    "node_1_output = np.tanh(node_1_input)\n",
    "\n",
    "hidden_layer_values = np.array([node_0_output,node_1_output])\n",
    "\n",
    "output = (hidden_layer_values * weights['output']).sum() #Dot product\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "#With RELU\n",
    "\n",
    "def relu(input):\n",
    "    '''Define your relu activation function here'''\n",
    "    # Calculate the value for the output of the relu function: output\n",
    "    output = max(0, input)\n",
    "    \n",
    "    # Return the value just calculated\n",
    "    return(output)\n",
    "\n",
    "# Calculate node 0 value: node_0_output\n",
    "node_0_input = (input_data * weights['node_0']).sum()\n",
    "node_0_output = relu(node_0_input)\n",
    "\n",
    "# Calculate node 1 value: node_1_output\n",
    "node_1_input = (input_data * weights['node_1']).sum()\n",
    "node_1_output = relu(node_1_input)\n",
    "\n",
    "# Put node values into array: hidden_layer_outputs\n",
    "hidden_layer_outputs = np.array([node_0_output, node_1_output])\n",
    "\n",
    "# Calculate model output (do not apply relu)\n",
    "model_output = (hidden_layer_outputs * weights['output']).sum()\n",
    "\n",
    "# Print model output\n",
    "print(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 12]\n"
     ]
    }
   ],
   "source": [
    "# Applied to many observations\n",
    "\n",
    "# Define predict_with_network()\n",
    "def predict_with_network(input_data_row, weights):\n",
    "\n",
    "    # Calculate node 0 value\n",
    "    node_0_input = (input_data_row * weights['node_0']).sum()\n",
    "    node_0_output = relu(node_0_input)\n",
    "\n",
    "    # Calculate node 1 value\n",
    "    node_1_input = (input_data_row * weights['node_1']).sum()\n",
    "    node_1_output = relu(node_1_input)\n",
    "\n",
    "    # Put node values into array: hidden_layer_outputs\n",
    "    hidden_layer_outputs = np.array([node_0_output, node_1_output])\n",
    "    \n",
    "    # Calculate model output\n",
    "    input_to_final_layer = (hidden_layer_outputs * weights['output']).sum()\n",
    "    model_output = relu(input_to_final_layer)\n",
    "    \n",
    "    # Return model output\n",
    "    return(model_output)\n",
    "\n",
    "# Create empty list to store prediction results\n",
    "results = []\n",
    "for input_data_row in input_data:\n",
    "    # Append prediction to results\n",
    "    results.append(predict_with_network(input_data_row, weights))\n",
    "\n",
    "# Print results\n",
    "print(results)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deeper networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In a model for image recognition, we have this example:\n",
    "1. First hidden layers, identify lines (horizontal, vertical, diagonal)\n",
    "2. Find larger patterns like big squares\n",
    "3. Later layers might put together the location of squares and geometric shapes, to identify a face, a car, etc.\n",
    "\n",
    "We don't need to specify those interactions/patterns, the NN gets weights that find the relevant patterns to make better predictions.\n",
    "\n",
    "**NOTES** \n",
    "- The model training process sets them to optimize predictive accuracy.\n",
    "- The last layers capture the most complex interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With 2 hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n"
     ]
    }
   ],
   "source": [
    "weights = {'node_0_0': np.array([2, 4]),\n",
    " 'node_0_1': np.array([ 4, -5]),\n",
    " 'node_1_0': np.array([-1,  2]),\n",
    " 'node_1_1': np.array([1, 2]),\n",
    " 'output': np.array([2, 7])}\n",
    "\n",
    "def predict_with_network(input_data):\n",
    "    # Calculate node 0 in the first hidden layer\n",
    "    node_0_0_input = (input_data * weights['node_0_0']).sum()\n",
    "    node_0_0_output = relu(node_0_0_input)\n",
    "\n",
    "    # Calculate node 1 in the first hidden layer\n",
    "    node_0_1_input = (input_data * weights['node_0_1']).sum()\n",
    "    node_0_1_output = relu(node_0_1_input)\n",
    "\n",
    "    # Put node values into array: hidden_0_outputs\n",
    "    hidden_0_outputs = np.array([node_0_0_output, node_0_1_output])\n",
    "    \n",
    "    # Calculate node 0 in the second hidden layer\n",
    "    node_1_0_input = (hidden_0_outputs * weights['node_1_0']).sum()\n",
    "    node_1_0_output = relu(node_1_0_input)\n",
    "\n",
    "    # Calculate node 1 in the second hidden layer\n",
    "    node_1_1_input = (hidden_0_outputs * weights['node_1_1']).sum()\n",
    "    node_1_1_output = relu(node_1_1_input)\n",
    "\n",
    "    # Put node values into array: hidden_1_outputs\n",
    "    hidden_1_outputs = np.array([node_1_0_output, node_1_1_output])\n",
    "\n",
    "    # Calculate model output: model_output\n",
    "    model_output = (hidden_1_outputs * weights['output']).sum()\n",
    "    \n",
    "    # Return model_output\n",
    "    return(model_output)\n",
    "\n",
    "output = predict_with_network(input_data)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing a neural network with backward propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lower loss function value means a better model. It can be modeled in a 3D space, where X and Y are the weights, and Z is the value from the loss function.\n",
    "\n",
    "The goal is to find the values for weights, where we have the lowest value for the loss function. The algorithm used is \"gradient descent\", which uses the slope to find a flat point in the function.\n",
    "\n",
    "The steps are:\n",
    "1. Find the slope\n",
    "2. Take a step downhill\n",
    "3. Repeat until you get to the mi value where the slope/derivative is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# The data point you will make a prediction for\n",
    "input_data = np.array([0, 3])\n",
    "\n",
    "# Sample weights\n",
    "weights_0 = {'node_0': [2, 1],\n",
    "             'node_1': [1, 2],\n",
    "             'output': [1, 1]\n",
    "            }\n",
    "\n",
    "# The actual target value, used to calculate the error\n",
    "target_actual = 3\n",
    "\n",
    "# Make prediction using original weights\n",
    "model_output_0 = predict_with_network(input_data, weights_0)\n",
    "\n",
    "# Calculate error: error_0\n",
    "error_0 = model_output_0 - target_actual\n",
    "\n",
    "# Create weights that cause the network to make perfect prediction (3): weights_1\n",
    "weights_1 = {'node_0': [2, 1],\n",
    "             'node_1': [1, 2],\n",
    "             'output': [1, 0]\n",
    "            }\n",
    "\n",
    "# Make prediction using new weights: model_output_1\n",
    "model_output_1 = predict_with_network(input_data, weights_1)\n",
    "\n",
    "# Calculate error: error_1\n",
    "error_1 = model_output_1 - target_actual\n",
    "\n",
    "# Print error_0 and error_1\n",
    "print(error_0)\n",
    "print(error_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error with weights_0: 37.500000\n",
      "Mean squared error with weights_1: 7.750000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Create model_output_0 \n",
    "model_output_0 = []\n",
    "# Create model_output_1\n",
    "model_output_1 = []\n",
    "\n",
    "target_actuals = [1, 3, 5, 7]\n",
    "\n",
    "input_data = [np.array([0, 3]), np.array([1, 2]), np.array([-1, -2]), np.array([4, 0])]\n",
    "\n",
    "# Loop over input_data\n",
    "for row in input_data:\n",
    "    # Append prediction to model_output_0\n",
    "    model_output_0.append(predict_with_network(row, weights_0))\n",
    "    \n",
    "    # Append prediction to model_output_1\n",
    "    model_output_1.append(predict_with_network(row, weights_1))\n",
    "\n",
    "# Calculate the mean squared error for model_output_0: mse_0\n",
    "mse_0 = mean_squared_error(target_actuals,model_output_0)\n",
    "\n",
    "# Calculate the mean squared error for model_output_1: mse_1\n",
    "mse_1 = mean_squared_error(target_actuals,model_output_1)\n",
    "\n",
    "# Print mse_0 and mse_1\n",
    "print(\"Mean squared error with weights_0: %f\" %mse_0)\n",
    "print(\"Mean squared error with weights_1: %f\" %mse_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradinet descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is used to optimize weights in a model, if slope is positive:\n",
    "* Move to lower numbers\n",
    "* Substract the slope from the current Value\n",
    "* Too big step might lead us astray\n",
    "\n",
    "So, insted of directly substracting the slope, we multiply the slope by a small number, called **learning rate**.\n",
    "\n",
    "Solution: Learning Rate\n",
    "- Update each weight by substracting $LearningRate * Slope$\n",
    "    - $NewWeight = Weight - LearningRate * Slope$\n",
    "- LR are frequently around 0.01\n",
    "- This ensures small steps to reach the optmal weights\n",
    "\n",
    "(3) --2--> (6)\n",
    "Target = 10\n",
    "\n",
    "$SlopeForWeight -Or- GradientsForWeights = $\\\n",
    "(Slope of the loss function respect the output node) --> 2*(PredictedValue-ActualValue) Or 2*Error = 2(-4)\\\n",
    "(Input Data) --> 3\\\n",
    "(Slope of activation funtion we feed) --> In this case is the identity.\n",
    "\n",
    "$SlopeForWeight = 2*-4*3$ \\\n",
    "$SlopeForWeight = -24$\n",
    "\n",
    "If learning_rate = 0.01, the new weight would be: \n",
    " \n",
    "$2 - (-24 * 0.01) = 2.24$\n",
    "\n",
    "Then,  repeat this for each weight for multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "[0.7 1.6]\n",
      "2.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "weights = np.array([1, 2])\n",
    "input_data = np.array([3, 4])\n",
    "target = 6\n",
    "learning_rate = 0.01\n",
    "preds = (weights * input_data).sum()\n",
    "error = preds - target\n",
    "print(error)\n",
    "\n",
    "#Slope\n",
    "gradient = 2* input_data * error\n",
    "\n",
    "weights_updated = weights - learning_rate * gradient\n",
    "print(weights_updated)\n",
    "preds_updated = (weights_updated * input_data).sum()\n",
    "error_updated = preds_updated - target\n",
    "print(error_updated)\n",
    "\n",
    "#Great work! As you can see, the mean squared error decreases as the number of iterations go up.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is used to calculate the slopes you need to optimize more complex deep learning models.\n",
    "\n",
    "It calculates the necessary slopes sequentially from the weights closest to the prediction, through the hidden layers, eventually back to the weights coming from the inputs.\n",
    "\n",
    "* Trying to estimate the slope of the loss function w.r.t. each weight\n",
    "* First Forward propagation to calculate predictions and errors\n",
    "\n",
    "Each time you generate predictions using forward propagation, you update the weights using backward propagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = 4\n",
    "# error = 3 \n",
    "# ReLU = 1, since the output node is positive\n",
    "\n",
    "# (1) -1-> (7)\n",
    "# (3) -2-/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Start at some random set of weights\n",
    "2. Use forward propagation to make a prediction\n",
    "3. Use backward propagation to calculate the slope of the loss function w.r.t. each weight\n",
    "4. Multiply that slope by the learning rate, and substract from the current weights\n",
    "4. Keep going until we get to a flat part\n",
    "\n",
    "##### Stochastic gradient descent\n",
    "* ItÂ´s common to calculate slopes on only a subset of the data (called a batch)\n",
    "* Use a different batch of data to calculate the next update\n",
    "* Start over from the beggining once all data is used\n",
    "* Each time through the training data is called an epoch\n",
    "* When slopes are calculated on one batch at a time, is called **stochastic gradient descent**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building deep learning models with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model building steps:\n",
    "1. Specify Architecture (Layers, nodes, activation functions)\n",
    "2. Compile\n",
    "3. Fit\n",
    "4. Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "#Code\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "path = r'C:\\Users\\LLerma\\Documents\\GitHub\\Learning\\Datasets'\n",
    "\n",
    "predictors = np.loadtxt(path + '\\predictors_data.csv', delimiter = ',')\n",
    "n_cols = predictors.shape[1] #Number of nodes in input layer\n",
    "\n",
    "model = Sequential() #An easy way with simple connections\n",
    "\n",
    "#In Dense layers, all the nodes in the previous layer connect to all the nodes in the current layer. \n",
    "#Here, we add layers\n",
    "model.add(Dense(100, activation='relu', input_shape = (n_cols,))) #100 nodes, activation function\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(1)) #A single output layer \n",
    "\n",
    "#This model has 2 hidden layers and an output layer\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Compiling and fitting a model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates an inernal function to do back-propagation effitiently.\n",
    "\n",
    "It has two main arguments:\n",
    "\n",
    "1. Optimizer (which controls the learning rate)\n",
    "    - 'Adam' is a good LR optimizer  \n",
    " \n",
    "2. Loss function\n",
    "    - MSE ia common for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "#Code to compile\n",
    "n_cols = predictors.shape[1] #Number of nodes in input layer\n",
    "\n",
    "model = Sequential() #An easy way with simple connections\n",
    "\n",
    "#In Dense layers, all the nodes in the previous layer connect to all the nodes in the current layer. \n",
    "#Here, we add layers\n",
    "model.add(Dense(100, activation='relu', input_shape = (n_cols,))) #100 nodes, activation function\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(1)) #A single output layer \n",
    "\n",
    "model.compile(optimzer='adam', loss='mean_squared_error')\n",
    "\n",
    "#Scaling data before fitting can ease optimization\n",
    "model.fit(predictors, target)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Loss function: **'categorical_crossentropy'** \n",
    "* Instead of MSE, and is the most common. \n",
    "* AKA as LogLoss, where: Lower scores are better.\n",
    "* Add 'metrics = ['accuracy'], to compile step for easy-to-understand diagnostics and prints accuracy.\n",
    "* Ouput layer has separte node for each possible outcome, and uses **'softmax'** activation. (to be able to interpret as porobabilities)\n",
    "* 'sgd' optimizer, which stands for Stochastic Gradient Descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "#Code\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "data = np.loadtxt(path + '\\basketball_data.csv', delimiter = ',')\n",
    "predictors = data.drop(['shot_result'], axis=1).values\n",
    "target = to_categorical(data['shot_result'])\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(100, activation='relu', input_shape = (n_cols,))) #100 nodes, activation function\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax')) #A double output layer \n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(predictors, target)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 907us/step - loss: 1.9930 - accuracy: 0.5915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x213a45e0970>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "\n",
    "path = r'C:\\Users\\LLerma\\Documents\\GitHub\\Learning\\Datasets'\n",
    "df = pd.read_csv(path + r'\\titanic_all_numeric.csv', delimiter = ',')\n",
    "\n",
    "predictors = df.drop(['survived'], axis=1).values\n",
    "predictors = np.asarray(predictors).astype('float32')\n",
    "# Convert the target to categorical: target\n",
    "target = to_categorical(df.survived)\n",
    "\n",
    "n_cols = predictors.shape[1]\n",
    "\n",
    "# Set up the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first layer\n",
    "model.add(Dense(32, activation='relu', input_shape=(n_cols,)))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(predictors, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.8684881, 0.1315119]], dtype=float32)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(predictors[0:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Save\n",
    "2. Reload\n",
    "3. Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "from tensforlow.keras.models import load_model\n",
    "model.save('model_file.h5')\n",
    "my_model = load_model('model_file.h5')\n",
    "predictions = my_model.predict(data_to_predict_with)\n",
    "\n",
    "#To get only success probabilities\n",
    "probability_true = predictions[:,1]\n",
    "\n",
    "#View summary\n",
    "my_model.summary()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning Keras models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dying neuron problem occurs when a neuron takes a value less than 0 for all of the data.\n",
    "\n",
    "The vanishing gradients problem. occurs when many layers have very small slopes and in deep networks, updates to backprop were close to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Testing model with learning rate: 0.000001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Otro\\Anaconda\\envs\\GPU_AMI\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 922us/step - loss: 2.2216\n",
      "\n",
      "\n",
      "Testing model with learning rate: 0.010000\n",
      "\n",
      "28/28 [==============================] - 0s 850us/step - loss: 1.2472\n",
      "\n",
      "\n",
      "Testing model with learning rate: 1.000000\n",
      "\n",
      "28/28 [==============================] - 0s 923us/step - loss: 6291748864.0000\n"
     ]
    }
   ],
   "source": [
    "# Import the SGD optimizer\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "path = r'C:\\Users\\LLerma\\Documents\\GitHub\\Learning\\Datasets'\n",
    "df = pd.read_csv(path + r'\\titanic_all_numeric.csv', delimiter = ',')\n",
    "\n",
    "predictors = df.drop(['survived'], axis=1).values\n",
    "predictors = np.asarray(predictors).astype('float32')\n",
    "# Convert the target to categorical: target\n",
    "target = to_categorical(df.survived)\n",
    "\n",
    "\n",
    "def get_new_model(input_shape=(n_cols,)):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, activation='relu', input_shape=input_shape))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    return(model)\n",
    "\n",
    "# Create list of learning rates: lr_to_test\n",
    "lr_to_test = [0.000001, 0.01, 1]\n",
    "\n",
    "# Loop over learning rates\n",
    "for lr in lr_to_test:\n",
    "    print('\\n\\nTesting model with learning rate: %f\\n'%lr )\n",
    "    \n",
    "    # Build new model to test, unaffected by previous models\n",
    "    model = get_new_model()\n",
    "    \n",
    "    # Create SGD optimizer with specified learning rate: my_optimizer\n",
    "    my_optimizer = SGD(lr=lr)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer = my_optimizer, loss = 'categorical_crossentropy')\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(predictors, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* K-fold cross validation is not usually used, because deep learning models are run on large datasets\n",
    "* Single vlaidation score is based on large amount of daa, and is reliable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 1.0804 - accuracy: 0.6164 - val_loss: 0.6530 - val_accuracy: 0.6940\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6336 - accuracy: 0.6774 - val_loss: 0.6739 - val_accuracy: 0.6604\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6616 - accuracy: 0.6421 - val_loss: 0.5565 - val_accuracy: 0.7612\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6012 - accuracy: 0.7095 - val_loss: 0.5125 - val_accuracy: 0.7463\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5676 - accuracy: 0.7207 - val_loss: 0.5598 - val_accuracy: 0.7425\n"
     ]
    }
   ],
   "source": [
    "# Import EarlyStopping\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Save the number of columns in predictors: n_cols\n",
    "n_cols = predictors.shape[1]\n",
    "input_shape = (n_cols,)\n",
    "\n",
    "# Specify the model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape = input_shape))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define early_stopping_monitor\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(predictors, target, validation_split=0.3, callbacks=[early_stopping_monitor], epochs=5)\n",
    "\n",
    "# In this case, the model will run 5 epochs, except if it's stopped by the EarlyStopping\n",
    "# Patience: How many epochs the model can go withput improving before we stop training. 2 or 3 are reasonable\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "# Callbacks is a list, and can be used many callbacks\n",
    "# By default Keras uses 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define early_stopping_monitor\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "\n",
    "# Create the new model: model_2\n",
    "model_2 = Sequential()\n",
    "\n",
    "# Add the first and second layers\n",
    "model_2.add(Dense(100, activation='relu', input_shape=input_shape))\n",
    "model_2.add(Dense(100, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model_2.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile model_2\n",
    "model_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit model_1\n",
    "model_1_training = model.fit(predictors, target, epochs=15, validation_split=0.2, callbacks=[early_stopping_monitor], verbose=False)\n",
    "\n",
    "# Fit model_2\n",
    "model_2_training = model_2.fit(predictors, target, epochs=15, validation_split=0.2, callbacks=[early_stopping_monitor], verbose=False)\n",
    "\n",
    "# Create the plot\n",
    "plt.plot(model_1_training.history['val_loss'], 'r', model_2_training.history['val_loss'], 'b')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model capacity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or network capacity, is closely related to the terms overfitting and underfitting. Increasing the number of nodes or the hidden layers, increases the model capacity.\n",
    "\n",
    "1. Start with a small network\n",
    "2. Gradually increase capacity\n",
    "3. Keep increasing capacity until validation socre is no longer improving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is an open source lubrary for graph-based numerical computation developed by google.\n",
    "\n",
    "* low and high level APIs\n",
    "* Machine learning models\n",
    "\n",
    "A tensor is a  generalization of vectors and matrices to potentially higher dimensions.\n",
    "\n",
    "```py\n",
    "- tf.constant()\n",
    "- tf.zeros()\n",
    "- tf.zeros_like(input_tensor)\n",
    "- tf.ones()\n",
    "- tf.ones_like(input_tensor)\n",
    "- tf.fill([3,3], 7)\n",
    "- tensor.numpy() #To change to a numpy array\n",
    "```\n",
    "\n",
    "TensorFlow extensions:\n",
    "\n",
    "1. TensorFlow Hub\n",
    "    - Pretrained models\n",
    "    - Transfer learning\n",
    "\n",
    "2. Tensorflow Probability\n",
    "    - Statistical distributions\n",
    "    - Trainable distributions\n",
    "    - Extended set of optimizers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1.], shape=(1,), dtype=float32) \n",
      "\n",
      "tf.Tensor([1. 1.], shape=(2,), dtype=float32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[1. 1.]\n",
      " [1. 1.]], shape=(2, 2), dtype=float32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[[1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]]], shape=(2, 2, 2), dtype=float32) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 0D Tensor\n",
    "d0 = tf.ones((1,))\n",
    "print(d0,\"\\n\")\n",
    "\n",
    "# 1D Tensor\n",
    "d1 = tf.ones((2,))\n",
    "print(d1,\"\\n\")\n",
    "\n",
    "# 2D Tensor\n",
    "d2 = tf.ones((2,2))\n",
    "print(d2,\"\\n\")\n",
    "\n",
    "# 3D Tensor\n",
    "d3 = tf.ones((2,2,2))\n",
    "print(d3,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Not trainable\n",
    "* Can have any dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[3 3 3]\n",
      " [3 3 3]], shape=(2, 3), dtype=int32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import constant\n",
    "\n",
    "a = constant(3, shape=[2,3])\n",
    "print(a,\"\\n\")\n",
    "\n",
    "\n",
    "b = constant([1,2,3,4], shape=[2,2])\n",
    "print(b,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(6,) dtype=float32, numpy=array([1., 2., 3., 4., 5., 6.], dtype=float32)> \n",
      "\n",
      "<tf.Variable 'Variable:0' shape=(6,) dtype=int16, numpy=array([1, 2, 3, 4, 5, 6], dtype=int16)> \n",
      "\n",
      "tf.Tensor([ 2.  4.  6.  8. 10. 12.], shape=(6,), dtype=float32) \n",
      "\n",
      "tf.Tensor([ 2.  4.  6.  8. 10. 12.], shape=(6,), dtype=float32) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "a0 = tf.Variable([1,2,3,4,5,6], dtype=tf.float32)\n",
    "print(a0,\"\\n\")\n",
    "a1 = tf.Variable([1,2,3,4,5,6], dtype=tf.int16)\n",
    "print(a1,\"\\n\")\n",
    "\n",
    "b = tf.constant(2, tf.float32)\n",
    "\n",
    "c0 = tf.multiply(a0,b)\n",
    "print(c0,\"\\n\")\n",
    "c1 = a0*b\n",
    "print(c1,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow has a model of computation that revolves around the use of graphs.\n",
    "* Edges are tensors\n",
    "* Nodes are operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import constant, add, reduce_sum\n",
    "\n",
    "A0 = constant([1])\n",
    "B0 = constant([2])\n",
    "\n",
    "A1 = constant([1,2])\n",
    "B1 = constant([3,4])\n",
    "\n",
    "A2 = constant([[1,2],[3,4]])\n",
    "B2 = constant([[5,6],[7,8]])\n",
    "\n",
    "C0 = A0+B0\n",
    "C1 = A1+B1\n",
    "C2 = A2+B2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For multiplication:\n",
    "\n",
    "* multiply\n",
    "* madmul() - For matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summing over tensors dimensions\n",
    "\n",
    "```py\n",
    "reduce_sum() # Sums over the dimensions of a tensor\n",
    "reduce_sum(A) # Sums over all dimensions of A\n",
    "reduce_sum(A,i) # Sums over dimension i\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=24.0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce_sum(ones([2,3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[4., 4., 4.],\n",
       "       [4., 4., 4.]], dtype=float32)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce_sum(ones([2,3,4]), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$features*params=prediction$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1687]\n",
      " [-3218]\n",
      " [-1933]\n",
      " [57850]]\n"
     ]
    }
   ],
   "source": [
    "# Define features, params, and bill as constants\n",
    "features = constant([[2, 24], [2, 26], [2, 57], [1, 37]])\n",
    "params = constant([[1000], [150]])\n",
    "bill = constant([[3913], [2682], [8617], [64400]])\n",
    "\n",
    "# Compute billpred using features and params\n",
    "billpred = matmul(features,params)\n",
    "\n",
    "# Compute and print the error\n",
    "error = bill - billpred\n",
    "print(error.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advanced Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* gradient() - Computes the slope of a function at a point\n",
    "* reshape() - Reshapes a tensor (e.g. 10x10 to 100x1)\n",
    "* random() - Populates tensor with entries drawn from a probability distribution\n",
    "\n",
    "The gradient operation tells us the slope pf a function at a point. The optimum point, is where the gradient=0. \n",
    "* Minimum: Change in gradient > 0\n",
    "* Maximum: Change in gradient <> 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.0\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable (-1.0)\n",
    "\n",
    "with tf.GradientTape() as tape_:\n",
    "    tape_.watch(x) # Allows to compute the rate of change of y respect to x\n",
    "    y= x*x\n",
    "\n",
    "g = tape_.gradient(y,x)\n",
    "print(g.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.0\n",
      "2.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#Other way\n",
    "\n",
    "def compute_gradient(x0):\n",
    "  \t# Define x as a variable with an initial value of x0\n",
    "\tx = tf.Variable(x0)\n",
    "\twith tf.GradientTape() as tape_:\n",
    "\t\ttape_.watch(x)\n",
    "        # Define y using the multiply operation\n",
    "\t\ty = multiply(x,x)\n",
    "    # Return the gradient of y with respect to x\n",
    "\treturn tape_.gradient(y, x).numpy()\n",
    "\n",
    "# Compute and print gradients at x = -1, 1, and 0\n",
    "print(compute_gradient(-1.0))\n",
    "print(compute_gradient(1.0))\n",
    "print(compute_gradient(0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[175,  72],\n",
       "       [242, 234]])>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray = tf.random.uniform([2,2], maxval=255, dtype='int32')\n",
    "gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 1), dtype=int32, numpy=\n",
       "array([[175],\n",
       "       [ 72],\n",
       "       [242],\n",
       "       [234]])>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "gray = tf.reshape(gray, [2*2, 1])\n",
    "gray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  ...     long  sqft_living15  sqft_lot15\n",
       "0  7129300520  20141013T000000  221900.0  ... -122.257           1340        5650\n",
       "1  6414100192  20141209T000000  538000.0  ... -122.319           1690        7639\n",
       "2  5631500400  20150225T000000  180000.0  ... -122.233           2720        8062\n",
       "3  2487200875  20141209T000000  604000.0  ... -122.393           1360        5000\n",
       "4  1954400510  20150218T000000  510000.0  ... -122.045           1800        7503\n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "path = r'C:\\Users\\LLerma\\Documents\\GitHub\\Learning\\Datasets'\n",
    "\n",
    "housing = pd.read_csv(path + r'\\kc_house_data.csv', delimiter = ',')\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LLerma\\AppData\\Local\\Temp\\ipykernel_21428\\3007825780.py:3: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  waterfront = np.array(housing['waterfront'], np.bool)\n"
     ]
    }
   ],
   "source": [
    "#With numpy\n",
    "price = np.array(housing['price'], np.float32)\n",
    "waterfront = np.array(housing['waterfront'], np.bool)\n",
    "\n",
    "#With tf\n",
    "price_tf = tf.cast(housing['price'], tf.float32)\n",
    "waterfront_tf = tf.cast(housing['waterfront'], tf.bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typical loss functions in linear models:\n",
    "\n",
    "```py\n",
    "- tf.keras.losses.mse() #Mean squared error (MSE)\n",
    "- tf.keras.losses.mae() #Mean absoulte error (MAE)\n",
    "- tf.keras.losses.Huber() #Huber error\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* MSE \n",
    "    - Strongly penalizes outliers\n",
    "    - High (gradient) sensitivity near minimum\n",
    "* MAE\n",
    "    - Scales linearly with size of error\n",
    "    - Low sensitivity near minimum\n",
    "    - Minimize the impact of outliers\n",
    "* Huber\n",
    "    - Similar to MSE near minimum\n",
    "    - Similar to MAE away from minimum\n",
    "    - Minimize the impact of outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code\n",
    "\n",
    "```py\n",
    "#Compute MSE loss\n",
    "loss = tf.keras.losses.mse(targets, predictions)\n",
    "\n",
    "#Linear Regression model\n",
    "def linear_regression(intercept, slope, features):\n",
    "    return intercept + features*slope\n",
    "\n",
    "#Loss function to compute MSE\n",
    "def loss_function(intercept, slope, targets, features):\n",
    "    predictions = linear_regression(intercept, slope)\n",
    "    return tf.keras.losses.mse(targets, predictions)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is performed a np.log() operation for x and y, here is explained why:\\\n",
    "https://dev.to/rokaandy/logarithmic-transformation-in-linear-regression-models-why-when-3a7c\n",
    "\n",
    "$price = intercept + size*slope + error$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(np.array(housing['sqft_living']), np.array(housing['price']))\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(np.log(np.array(housing['sqft_living'])), (np.log(np.array(housing['price']))))\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.4664426\n",
      "2.4482296\n",
      "0.9850192\n",
      "0.4135866\n",
      "0.23932903\n",
      "0.19873808\n",
      "0.19155614\n",
      "0.19057396\n",
      "0.19044808\n",
      "0.1904085\n",
      "10.260733 0.37041798\n"
     ]
    }
   ],
   "source": [
    "price = np.log(np.array(housing['price'], np.float32))\n",
    "size = np.log(np.array(housing['sqft_living'], np.float32))\n",
    "\n",
    "intercept = tf.Variable(10., np.float32)\n",
    "slope = tf.Variable(0.1, np.float32)\n",
    "\n",
    "#Linear Regression model\n",
    "def linear_regression(intercept, slope, features=size):\n",
    "    return intercept + features*slope\n",
    "\n",
    "#Loss function to compute MSE\n",
    "def loss_function(intercept, slope, targets = price, features = size):\n",
    "    predictions = linear_regression(intercept, slope)\n",
    "    return tf.keras.losses.mse(targets, predictions)\n",
    "\n",
    "#Define an optimization operation\n",
    "opt = tf.keras.optimizers.Adam()\n",
    "\n",
    "#Minimize the loss function and print the loss\n",
    "for j in range(1000):\n",
    "    opt.minimize(lambda: loss_function(intercept,slope), var_list=[intercept,slope])\n",
    "\n",
    "#Print every 100 loops\n",
    "    if (j % 100) == 0:\n",
    "        print(loss_function(intercept, slope).numpy())\n",
    "\n",
    "print(intercept.numpy(), slope.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "slope_ = slope.numpy()\n",
    "intercept_ = intercept.numpy()\n",
    "x = np.log(np.array(housing['sqft_living']))\n",
    "\n",
    "plt.scatter(np.log(np.array(housing['sqft_living'])), np.log((np.array(housing['price']))))\n",
    "plt.plot(x, intercept_ + x*slope_, c='r')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In most cases, performing a univariate linear regression will not yield a model that is useful for making accurate predictions. In this exercise, you will perform a multiple regression, which uses more than one feature.\n",
    "\n",
    "You will use price_log as your target and size_log and bedrooms as your features. Each of these tensors has been defined and is available. You will also switch from using the the mean squared error loss to the mean absolute error loss: keras.losses.mae(). Finally, the predicted values are computed as follows: params[0] + feature1*params[1] + feature2*params[2]. Note that we've defined a vector of parameters, params, as a variable, rather than using three variables. Here, params[0] is the intercept and params[1] and params[2] are the slopes\n",
    "\n",
    "```py \n",
    "#Define the linear regression model\n",
    "def linear_regression(params, feature1 = size_log, feature2 = bedrooms):\n",
    "\treturn params[0] + feature1*params[1] + feature2*params[2]\n",
    "\n",
    "#Define the loss function\n",
    "def loss_function(params, targets = price_log, feature1 = size_log, feature2 = bedrooms):\n",
    "\t#Set the predicted values\n",
    "\tpredictions = linear_regression(params, feature1, feature2)\n",
    "  \n",
    "\t#Use the mean absolute error loss\n",
    "\treturn keras.losses.mae(targets, predictions)\n",
    "\n",
    "#Define the optimize operation\n",
    "opt = keras.optimizers.Adam()\n",
    "\n",
    "#Perform minimization and print trainable variables\n",
    "for j in range(10):\n",
    "\topt.minimize(lambda: loss_function(params), var_list=[params])\n",
    "\tprint_results(params)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Full sample: One update per epoch\n",
    "* Batch training: Multiple updates per epoch\n",
    "\n",
    "It can be donde directly with `pd.read_csv`, with the `chunksize` parameters\n",
    "\n",
    "```py\n",
    "for batch in pd.read_csv(path + r'\\kc_house_data.csv', chunksize = 100):\n",
    "    price = np.array(batch['price'], np.float32)\n",
    "    size = np.array(batch['size'], np.float32)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31799173 0.31615734\n"
     ]
    }
   ],
   "source": [
    "intercept = tf.Variable(0.1, tf.float32)\n",
    "slope = tf.Variable(0.1, tf.float32)\n",
    "\n",
    "#Linear Regression model\n",
    "def linear_regression(intercept, slope, features=size):\n",
    "    return intercept + features*slope\n",
    "\n",
    "#Loss function to compute MSE\n",
    "def loss_function(intercept, slope, targets = price, features = size):\n",
    "    predictions = linear_regression(intercept, slope, features)\n",
    "    return tf.keras.losses.mse(targets, predictions)\n",
    "\n",
    "opt = tf.keras.optimizers.Adam()\n",
    "\n",
    "for batch in pd.read_csv(path + r'\\kc_house_data.csv', chunksize = 100):\n",
    "    price_batch = np.array(batch['price'], np.float32)\n",
    "    size_batch = np.array(batch['sqft_living'], np.float32)\n",
    "\n",
    "    opt.minimize(lambda: loss_function(intercept, slope, price_batch, size_batch), var_list=[intercept,slope])\n",
    "\n",
    "print(intercept.numpy(), slope.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dense Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In dense layers, every weight is applied to all nodes from previous layer.\n",
    "\n",
    "- Bias is not asociated with a feature, and is analogous to the intercept in a linear regression\n",
    "* By default bias is included\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path + r'\\uci_credit_card.csv', delimiter = ',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Low level approach, using linear algebra operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "inputs = tf.constant([[1,35]], dtype='float32')\n",
    "weights = tf.Variable([[-0.05], [-0.01]])\n",
    "bias = tf.Variable([0.5])\n",
    "\n",
    "product = tf.matmul(inputs, weights) #Dot product\n",
    "dense = tf.keras.activations.sigmoid(product+bias)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High level approach, using API operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inputs layer\n",
    "inputs = tf.constant(df, tf.float32)\n",
    "\n",
    "#First Dense layer\n",
    "dense1 = tf.keras.layers.Dense(10, activation ='sigmoid')(inputs)\n",
    "\n",
    "dense2 = tf.keras.layers.Dense(5, activation ='sigmoid')(dense1)\n",
    "\n",
    "#Output layer\n",
    "output = tf.keras.layers.Dense(1, activation ='sigmoid')(dense2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py \n",
    "#High level approach with an input tensor [100x10]\n",
    "\n",
    "#Define the first dense layer\n",
    "dense1 = keras.layers.Dense(7, activation='sigmoid')(borrower_features)\n",
    "\n",
    "#Define a dense layer with 3 output nodes\n",
    "dense2 = keras.layers.Dense(3, activation='sigmoid')(dense1)\n",
    "\n",
    "#Define a dense layer with 1 output node\n",
    "predictions = keras.layers.Dense(1, activation='sigmoid')(dense2)\n",
    "\n",
    "#Print the shapes of dense1, dense2, and predictions\n",
    "print('\\n shape of dense1: ', dense1.shape)\n",
    "print('\\n shape of dense2: ', dense2.shape)\n",
    "print('\\n shape of predictions: ', predictions.shape)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sigmoid: In output layer of binary classification\n",
    "- ReLU: In all layers other than the output layer\n",
    "- Softmax: In output layer in clasification problem with more than two classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3 0.5 1.6 0.8\n",
      "Diff in default predictions for young 0.8\n",
      "Diff in default predictions for old 0.8\n",
      "Diff in default predictions for young (sigmod) 0.16337568\n",
      "Diff in default predictions for old (sigmod) 0.14204389\n"
     ]
    }
   ],
   "source": [
    "#Define example borrower features\n",
    " \n",
    "young, old = 0.3, 0.6\n",
    "low_bill, high_bill = 0.1, 0.5\n",
    "\n",
    "#Apply matrix multiplication step for all feature combinations\n",
    "young_high = 1.0*young + 2.0*high_bill\n",
    "young_low = 1.0*young + 2.0*low_bill\n",
    "old_high = 1.0*old + 2.0*high_bill\n",
    "old_low = 1.0*old + 2.0*low_bill\n",
    "\n",
    "print(young_high, young_low, old_high, old_low)\n",
    "\n",
    "print(\"Diff in default predictions for young\", young_high - young_low)\n",
    "\n",
    "print(\"Diff in default predictions for old\", old_high - old_low)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Diff in default predictions for young (sigmod)\",  tf.keras.activations.sigmoid(young_high).numpy() - tf.keras.activations.sigmoid(young_low).numpy())\n",
    "\n",
    "print(\"Diff in default predictions for old (sigmod)\", tf.keras.activations.sigmoid(old_high).numpy() - tf.keras.activations.sigmoid(old_low).numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]], shape=(5, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#Activation function in neural networks\n",
    "\n",
    "bill_amounts = df[['BILL_AMT1', 'BILL_AMT2','BILL_AMT3']]\n",
    "default = df['default.payment.next.month']\n",
    "\n",
    "# Construct input layer from features\n",
    "inputs = tf.constant(bill_amounts, tf.float32)\n",
    "default_tensor = tf.constant(default, tf.float32, shape=(len(default), 1))\n",
    "\n",
    "# Define first dense layer\n",
    "dense1 = tf.keras.layers.Dense(3, activation='relu')(inputs)\n",
    "\n",
    "# Define second dense layer\n",
    "dense2 = tf.keras.layers.Dense(2, activation='relu')(dense1)\n",
    "\n",
    "# Define output layer\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(dense2)\n",
    "\n",
    "# Print error for first five examples\n",
    "error = default_tensor[:5] - outputs.numpy()[:5]\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SGD\n",
    "    - Good for simple problems\n",
    "    - Simple and easy to interpret \n",
    "* Adam (adaptive moment)\n",
    "    - futher improvements\n",
    "    - Generally a good first choice\n",
    "    -Performs better with default parameter values\n",
    "* RMS (Root mean squared propagation)\n",
    "    - Applies a different LR to each feature, useful for high dimensional problems\n",
    "    - Allows for momentum to both build an decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.optimizers.SGD()\n",
    "\n",
    "tf.keras.optimizers.Adam()\n",
    "\n",
    "tf.keras.optimizers.RMSprop()\n",
    "\n",
    "\n",
    "def model(bias, weights, features=bill_amounts):\n",
    "    product = tf.matmul(features, weights)\n",
    "    return tf.keras.activations.sigmoid(product+bias)\n",
    "\n",
    "def loss_function(bias, weights, target=default, features = bill_amounts):\n",
    "    predictions = model(bias, weights)\n",
    "    return tf.keras.losses.binary_crossentropy(targets, predictions)\n",
    "\n",
    "opt = tf.keras.optimizers.RMSprop(learning_rate=0.01, momentum=0.9)\n",
    "#opt.minimize(lambda: loss_function(bias, weights), var_list = [bias, weights])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "loss_function() missing 1 required positional argument: 'weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\LLerma\\Documents\\GitHub\\Learning\\Python\\Deep_Learning.ipynb Cell 116\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LLerma/Documents/GitHub/Learning/Python/Deep_Learning.ipynb#Y316sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m opt \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mSGD(learning_rate\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LLerma/Documents/GitHub/Learning/Python/Deep_Learning.ipynb#Y316sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m100\u001b[39m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LLerma/Documents/GitHub/Learning/Python/Deep_Learning.ipynb#Y316sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \t\u001b[39m# Perform minimization using the loss function and x_1\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/LLerma/Documents/GitHub/Learning/Python/Deep_Learning.ipynb#Y316sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \topt\u001b[39m.\u001b[39;49mminimize(\u001b[39mlambda\u001b[39;49;00m: loss_function([x_1]), var_list\u001b[39m=\u001b[39;49m[x_1])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/LLerma/Documents/GitHub/Learning/Python/Deep_Learning.ipynb#Y316sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \t\u001b[39m# Perform minimization using the loss function and x_2\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/LLerma/Documents/GitHub/Learning/Python/Deep_Learning.ipynb#Y316sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \topt\u001b[39m.\u001b[39mminimize(\u001b[39mlambda\u001b[39;00m: loss_function(x_2), var_list\u001b[39m=\u001b[39m[x_2])\n",
      "File \u001b[1;32mc:\\Otro\\Anaconda\\envs\\GPU_AMI\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py:576\u001b[0m, in \u001b[0;36mOptimizerV2.minimize\u001b[1;34m(self, loss, var_list, grad_loss, name, tape)\u001b[0m\n\u001b[0;32m    545\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mminimize\u001b[39m(\u001b[39mself\u001b[39m, loss, var_list, grad_loss\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, tape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    546\u001b[0m     \u001b[39m\"\"\"Minimize `loss` by updating `var_list`.\u001b[39;00m\n\u001b[0;32m    547\u001b[0m \n\u001b[0;32m    548\u001b[0m \u001b[39m    This method simply computes gradient using `tf.GradientTape` and calls\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    574\u001b[0m \n\u001b[0;32m    575\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 576\u001b[0m     grads_and_vars \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compute_gradients(\n\u001b[0;32m    577\u001b[0m         loss, var_list\u001b[39m=\u001b[39;49mvar_list, grad_loss\u001b[39m=\u001b[39;49mgrad_loss, tape\u001b[39m=\u001b[39;49mtape\n\u001b[0;32m    578\u001b[0m     )\n\u001b[0;32m    579\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_gradients(grads_and_vars, name\u001b[39m=\u001b[39mname)\n",
      "File \u001b[1;32mc:\\Otro\\Anaconda\\envs\\GPU_AMI\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py:625\u001b[0m, in \u001b[0;36mOptimizerV2._compute_gradients\u001b[1;34m(self, loss, var_list, grad_loss, tape)\u001b[0m\n\u001b[0;32m    623\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m callable(var_list):\n\u001b[0;32m    624\u001b[0m     tape\u001b[39m.\u001b[39mwatch(var_list)\n\u001b[1;32m--> 625\u001b[0m loss \u001b[39m=\u001b[39m loss()\n\u001b[0;32m    626\u001b[0m \u001b[39mif\u001b[39;00m callable(var_list):\n\u001b[0;32m    627\u001b[0m     var_list \u001b[39m=\u001b[39m var_list()\n",
      "\u001b[1;32mc:\\Users\\LLerma\\Documents\\GitHub\\Learning\\Python\\Deep_Learning.ipynb Cell 116\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LLerma/Documents/GitHub/Learning/Python/Deep_Learning.ipynb#Y316sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m opt \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mSGD(learning_rate\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LLerma/Documents/GitHub/Learning/Python/Deep_Learning.ipynb#Y316sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m100\u001b[39m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LLerma/Documents/GitHub/Learning/Python/Deep_Learning.ipynb#Y316sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \t\u001b[39m# Perform minimization using the loss function and x_1\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/LLerma/Documents/GitHub/Learning/Python/Deep_Learning.ipynb#Y316sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \topt\u001b[39m.\u001b[39mminimize(\u001b[39mlambda\u001b[39;00m: loss_function([x_1]), var_list\u001b[39m=\u001b[39m[x_1])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/LLerma/Documents/GitHub/Learning/Python/Deep_Learning.ipynb#Y316sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \t\u001b[39m# Perform minimization using the loss function and x_2\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/LLerma/Documents/GitHub/Learning/Python/Deep_Learning.ipynb#Y316sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \topt\u001b[39m.\u001b[39mminimize(\u001b[39mlambda\u001b[39;00m: loss_function(x_2), var_list\u001b[39m=\u001b[39m[x_2])\n",
      "\u001b[1;31mTypeError\u001b[0m: loss_function() missing 1 required positional argument: 'weights'"
     ]
    }
   ],
   "source": [
    "# Initialize x_1 and x_2\n",
    "x_1 = tf.Variable(6.0,tf.float32)\n",
    "x_2 = tf.Variable(0.3,tf.float32)\n",
    "\n",
    "# Define the optimization operation\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "\n",
    "for j in range(100):\n",
    "\t# Perform minimization using the loss function and x_1\n",
    "\topt.minimize(lambda: loss_function(x_1), var_list=[x_1])\n",
    "\t# Perform minimization using the loss function and x_2\n",
    "\topt.minimize(lambda: loss_function(x_2), var_list=[x_2])\n",
    "\n",
    "# Print x_1 and x_2 as numpy arrays\n",
    "print(x_1.numpy(), x_2.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training a network in TensorFlow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Often need to initialize thousand of variables\n",
    "* Alternatively, draw initial values from dustribution\n",
    "    - Normal\n",
    "    - Uniform\n",
    "    - Glorot initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOW LEVEL\n",
    "\n",
    "weights = tf.Variable(tf.random.normal([500,500]))\n",
    "\n",
    "#Discard very large and very small draws\n",
    "weights = tf.Variable(tf.random.truncated_normal([500,500]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HIGH LEVEL\n",
    "\n",
    "#Default initializer\n",
    "dense = tf.keras.layers.Dense(32, activation='relu')\n",
    "\n",
    "#Zeros initializer\n",
    "dense = tf.keras.layers.Dense(32, activation='relu', kernel_initializer='zeros')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple solution for overfitting is to use `dropout`, an operation that will randomly drop the weights connected to certain nodes in a layer during the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "inputs = np.array(bill_amounts, np.float32)\n",
    "\n",
    "dense1 = tf.keras.layers.Dense(32, activation='relu')(inputs)\n",
    "dense2 = tf.keras.layers.Dense(16, activation='relu')(dense1)\n",
    "\n",
    "#Specifies to drop the weights connected to 25% of nodes randomly\n",
    "dropout1 = tf.keras.layers.Dropout(0.25)(dense2)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(dropout1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "cannot compute MatMul as input #1(zero-based) was expected to be a double tensor but is a float tensor [Op:MatMul]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\LLerma\\Documents\\GitHub\\Learning\\Python\\Deep_Learning.ipynb Cell 124\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/LLerma/Documents/GitHub/Learning/Python/Deep_Learning.ipynb#Y331sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/LLerma/Documents/GitHub/Learning/Python/Deep_Learning.ipynb#Y331sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m100\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/LLerma/Documents/GitHub/Learning/Python/Deep_Learning.ipynb#Y331sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     \u001b[39m# Complete the optimizer\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/LLerma/Documents/GitHub/Learning/Python/Deep_Learning.ipynb#Y331sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \topt\u001b[39m.\u001b[39;49mminimize(\u001b[39mlambda\u001b[39;49;00m: loss_function(w1, b1, w2, b2), \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/LLerma/Documents/GitHub/Learning/Python/Deep_Learning.ipynb#Y331sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m                  var_list\u001b[39m=\u001b[39;49m[w1, b1, w2, b2])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/LLerma/Documents/GitHub/Learning/Python/Deep_Learning.ipynb#Y331sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m# Make predictions with model using test features\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/LLerma/Documents/GitHub/Learning/Python/Deep_Learning.ipynb#Y331sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m model_predictions \u001b[39m=\u001b[39m model(w1, b1, w2, b2, test_features)\n",
      "File \u001b[1;32mc:\\Otro\\Anaconda\\envs\\GPU_AMI\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py:576\u001b[0m, in \u001b[0;36mOptimizerV2.minimize\u001b[1;34m(self, loss, var_list, grad_loss, name, tape)\u001b[0m\n\u001b[0;32m    545\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mminimize\u001b[39m(\u001b[39mself\u001b[39m, loss, var_list, grad_loss\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, tape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    546\u001b[0m     \u001b[39m\"\"\"Minimize `loss` by updating `var_list`.\u001b[39;00m\n\u001b[0;32m    547\u001b[0m \n\u001b[0;32m    548\u001b[0m \u001b[39m    This method simply computes gradient using `tf.GradientTape` and calls\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    574\u001b[0m \n\u001b[0;32m    575\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 576\u001b[0m     grads_and_vars \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compute_gradients(\n\u001b[0;32m    577\u001b[0m         loss, var_list\u001b[39m=\u001b[39;49mvar_list, grad_loss\u001b[39m=\u001b[39;49mgrad_loss, tape\u001b[39m=\u001b[39;49mtape\n\u001b[0;32m    578\u001b[0m     )\n\u001b[0;32m    579\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_gradients(grads_and_vars, name\u001b[39m=\u001b[39mname)\n",
      "File \u001b[1;32mc:\\Otro\\Anaconda\\envs\\GPU_AMI\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py:625\u001b[0m, in \u001b[0;36mOptimizerV2._compute_gradients\u001b[1;34m(self, loss, var_list, grad_loss, tape)\u001b[0m\n\u001b[0;32m    623\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m callable(var_list):\n\u001b[0;32m    624\u001b[0m     tape\u001b[39m.\u001b[39mwatch(var_list)\n\u001b[1;32m--> 625\u001b[0m loss \u001b[39m=\u001b[39m loss()\n\u001b[0;32m    626\u001b[0m \u001b[39mif\u001b[39;00m callable(var_list):\n\u001b[0;32m    627\u001b[0m     var_list \u001b[39m=\u001b[39m var_list()\n",
      "\u001b[1;32mc:\\Users\\LLerma\\Documents\\GitHub\\Learning\\Python\\Deep_Learning.ipynb Cell 124\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/LLerma/Documents/GitHub/Learning/Python/Deep_Learning.ipynb#Y331sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/LLerma/Documents/GitHub/Learning/Python/Deep_Learning.ipynb#Y331sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m100\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/LLerma/Documents/GitHub/Learning/Python/Deep_Learning.ipynb#Y331sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     \u001b[39m# Complete the optimizer\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/LLerma/Documents/GitHub/Learning/Python/Deep_Learning.ipynb#Y331sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \topt\u001b[39m.\u001b[39mminimize(\u001b[39mlambda\u001b[39;00m: loss_function(w1, b1, w2, b2), \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/LLerma/Documents/GitHub/Learning/Python/Deep_Learning.ipynb#Y331sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m                  var_list\u001b[39m=\u001b[39m[w1, b1, w2, b2])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/LLerma/Documents/GitHub/Learning/Python/Deep_Learning.ipynb#Y331sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m# Make predictions with model using test features\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/LLerma/Documents/GitHub/Learning/Python/Deep_Learning.ipynb#Y331sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m model_predictions \u001b[39m=\u001b[39m model(w1, b1, w2, b2, test_features)\n",
      "\u001b[1;32mc:\\Users\\LLerma\\Documents\\GitHub\\Learning\\Python\\Deep_Learning.ipynb Cell 124\u001b[0m in \u001b[0;36mloss_function\u001b[1;34m(w1, b1, w2, b2, features, targets)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/LLerma/Documents/GitHub/Learning/Python/Deep_Learning.ipynb#Y331sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mloss_function\u001b[39m(w1, b1, w2, b2, features \u001b[39m=\u001b[39m bill_amounts, targets \u001b[39m=\u001b[39m default):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/LLerma/Documents/GitHub/Learning/Python/Deep_Learning.ipynb#Y331sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \tpredictions \u001b[39m=\u001b[39m model(w1, b1, w2, b2)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/LLerma/Documents/GitHub/Learning/Python/Deep_Learning.ipynb#Y331sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \t\u001b[39m# Pass targets and predictions to the cross entropy loss\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/LLerma/Documents/GitHub/Learning/Python/Deep_Learning.ipynb#Y331sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \t\u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mbinary_crossentropy(targets, predictions)\n",
      "\u001b[1;32mc:\\Users\\LLerma\\Documents\\GitHub\\Learning\\Python\\Deep_Learning.ipynb Cell 124\u001b[0m in \u001b[0;36mmodel\u001b[1;34m(w1, b1, w2, b2, features)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/LLerma/Documents/GitHub/Learning/Python/Deep_Learning.ipynb#Y331sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmodel\u001b[39m(w1, b1, w2, b2, features \u001b[39m=\u001b[39m bill_amounts):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/LLerma/Documents/GitHub/Learning/Python/Deep_Learning.ipynb#Y331sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \t\u001b[39m# Apply relu activation functions to layer 1\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/LLerma/Documents/GitHub/Learning/Python/Deep_Learning.ipynb#Y331sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \tlayer1 \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mactivations\u001b[39m.\u001b[39mrelu(tf\u001b[39m.\u001b[39;49mmatmul(features, w1) \u001b[39m+\u001b[39m b1)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/LLerma/Documents/GitHub/Learning/Python/Deep_Learning.ipynb#Y331sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39m# Apply dropout rate of 0.25\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/LLerma/Documents/GitHub/Learning/Python/Deep_Learning.ipynb#Y331sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \tdropout \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDropout(\u001b[39m0.25\u001b[39m)(layer1)\n",
      "File \u001b[1;32mc:\\Otro\\Anaconda\\envs\\GPU_AMI\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Otro\\Anaconda\\envs\\GPU_AMI\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:7209\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7207\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[0;32m   7208\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 7209\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: cannot compute MatMul as input #1(zero-based) was expected to be a double tensor but is a float tensor [Op:MatMul]"
     ]
    }
   ],
   "source": [
    "#Full Example\n",
    "\n",
    "# Define the layer 1 weights\n",
    "w1 = tf.Variable(tf.random.normal([23, 7]), tf.float32)\n",
    "\n",
    "# Initialize the layer 1 bias\n",
    "b1 = tf.Variable(tf.ones([7]), tf.float32)\n",
    "\n",
    "# Define the layer 2 weights\n",
    "w2 = tf.Variable(tf.random.normal([7, 1]), tf.float32)\n",
    "\n",
    "# Define the layer 2 bias\n",
    "b2 = tf.Variable(0.0, tf.float32)\n",
    "\n",
    "\n",
    "# Define the model\n",
    "def model(w1, b1, w2, b2, features = bill_amounts):\n",
    "\t# Apply relu activation functions to layer 1\n",
    "\tlayer1 = tf.keras.activations.relu(tf.matmul(features, w1) + b1)\n",
    "    # Apply dropout rate of 0.25\n",
    "\tdropout = tf.keras.layers.Dropout(0.25)(layer1)\n",
    "\treturn tf.keras.activations.sigmoid(tf.matmul(dropout, w2) + b2)\n",
    "\n",
    "# Define the loss function\n",
    "def loss_function(w1, b1, w2, b2, features = bill_amounts, targets = default):\n",
    "\tpredictions = model(w1, b1, w2, b2)\n",
    "\t# Pass targets and predictions to the cross entropy loss\n",
    "\treturn tf.keras.losses.binary_crossentropy(targets, predictions)\n",
    "\n",
    "\n",
    "# Train the model\n",
    "for j in range(100):\n",
    "    # Complete the optimizer\n",
    "\topt.minimize(lambda: loss_function(w1, b1, w2, b2), \n",
    "                 var_list=[w1, b1, w2, b2])\n",
    "\n",
    "# Make predictions with model using test features\n",
    "model_predictions = model(w1, b1, w2, b2, test_features)\n",
    "\n",
    "# Construct the confusion matrix\n",
    "confusion_matrix(test_targets, model_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High Level APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NN with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = keras.Sequential()\n",
    "\n",
    "#First layer\n",
    "model.add(Dense(16, activation='relu', input_shape=(28*28,)))\n",
    "\n",
    "#Second layer\n",
    "model.add(Dense(8, activation='relu'))\n",
    "\n",
    "#Output layer\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "#Compilation\n",
    "model.compile(activation = 'adam', loss='categorical_crossentropy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using two models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 784)]        0           []                               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 12)           9420        ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 8)            88          ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 4)            52          ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 4)            36          ['dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 4)            0           ['dense_11[0][0]',               \n",
      "                                                                  'dense_13[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 9,596\n",
      "Trainable params: 9,596\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model1_inputs = tf.keras.Input(shape=(28*28,))\n",
    "model2_inputs = tf.keras.Input(shape=(10,))\n",
    "\n",
    "model1_layer1 = Dense(12, activation='relu')(model1_inputs)\n",
    "model1_layer2 = Dense(4, activation='softmax')(model1_layer1)\n",
    "\n",
    "model2_layer1 = Dense(8, activation='relu')(model2_inputs)\n",
    "model2_layer2 = Dense(4, activation='softmax')(model2_layer1)\n",
    "\n",
    "#Merge model 1 and 2\n",
    "merged = tf.keras.layers.add([model1_layer2, model2_layer2])\n",
    "\n",
    "#Define a functional model\n",
    "\n",
    "model = tf.keras.Model(inputs=[model1_inputs, model2_inputs], outputs = merged)\n",
    "\n",
    "model.compile('adam', loss = 'categorical_crossentropy')\n",
    "\n",
    "# Print the model architecture\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and validation with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load and clean input_data\n",
    "2. Define model\n",
    "3. Train and validate model\n",
    "4. Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(Dense(16, activation='relu', input_shape = (784,)))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model.compile('adam', loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "#model.compile(optimizer=keras.optimizers.Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#model.fit(image_features, image_labels)\n",
    "\n",
    "#model.fit(image_features, image_labels, epoch=10, validation_split=0.2)\n",
    "\n",
    "#model.evaluate(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training models with the Estimators API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Define feature columns\n",
    "2. Load and transform daa\n",
    "3. Define an estimator\n",
    "4. Apply train operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\LLerma\\AppData\\Local\\Temp\\tmpmq7ayqx3\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\LLerma\\\\AppData\\\\Local\\\\Temp\\\\tmpmq7ayqx3', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Feature image is not in features dictionary.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\LLerma\\Documents\\GitHub\\Learning\\Python\\Deep_Learning.ipynb Cell 136\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/LLerma/Documents/GitHub/Learning/Python/Deep_Learning.ipynb#Y263sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m model0 \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mestimator\u001b[39m.\u001b[39mDNNRegressor(feature_columns \u001b[39m=\u001b[39m features_list, hidden_units\u001b[39m=\u001b[39m[\u001b[39m10\u001b[39m,\u001b[39m6\u001b[39m,\u001b[39m6\u001b[39m,\u001b[39m3\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/LLerma/Documents/GitHub/Learning/Python/Deep_Learning.ipynb#Y263sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m#Train the regression model\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/LLerma/Documents/GitHub/Learning/Python/Deep_Learning.ipynb#Y263sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m model0\u001b[39m.\u001b[39;49mtrain(input_fn, steps\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/LLerma/Documents/GitHub/Learning/Python/Deep_Learning.ipynb#Y263sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m#FOR CLASSIFICATION\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/LLerma/Documents/GitHub/Learning/Python/Deep_Learning.ipynb#Y263sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/LLerma/Documents/GitHub/Learning/Python/Deep_Learning.ipynb#Y263sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m#Define a deep NN classifier\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/LLerma/Documents/GitHub/Learning/Python/Deep_Learning.ipynb#Y263sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m model0 \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mestimator\u001b[39m.\u001b[39mDNNClassifier(feature_columns \u001b[39m=\u001b[39m features_list, hidden_units\u001b[39m=\u001b[39m[\u001b[39m32\u001b[39m,\u001b[39m16\u001b[39m,\u001b[39m8\u001b[39m], n_classes\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m)\n",
      "File \u001b[1;32mc:\\Otro\\Anaconda\\envs\\GPU_AMI\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:360\u001b[0m, in \u001b[0;36mEstimator.train\u001b[1;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[0;32m    357\u001b[0m hooks\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_convert_train_steps_to_hooks(steps, max_steps))\n\u001b[0;32m    359\u001b[0m saving_listeners \u001b[39m=\u001b[39m _check_listeners_type(saving_listeners)\n\u001b[1;32m--> 360\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_model(input_fn, hooks, saving_listeners)\n\u001b[0;32m    361\u001b[0m logging\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mLoss for final step: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m, loss)\n\u001b[0;32m    362\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Otro\\Anaconda\\envs\\GPU_AMI\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:1186\u001b[0m, in \u001b[0;36mEstimator._train_model\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1184\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_model_distributed(input_fn, hooks, saving_listeners)\n\u001b[0;32m   1185\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1186\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_model_default(input_fn, hooks, saving_listeners)\n",
      "File \u001b[1;32mc:\\Otro\\Anaconda\\envs\\GPU_AMI\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:1214\u001b[0m, in \u001b[0;36mEstimator._train_model_default\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1211\u001b[0m features, labels, input_hooks \u001b[39m=\u001b[39m (\n\u001b[0;32m   1212\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_features_and_labels_from_input_fn(input_fn, ModeKeys\u001b[39m.\u001b[39mTRAIN))\n\u001b[0;32m   1213\u001b[0m worker_hooks\u001b[39m.\u001b[39mextend(input_hooks)\n\u001b[1;32m-> 1214\u001b[0m estimator_spec \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_model_fn(features, labels, ModeKeys\u001b[39m.\u001b[39;49mTRAIN,\n\u001b[0;32m   1215\u001b[0m                                      \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig)\n\u001b[0;32m   1216\u001b[0m global_step_tensor \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mtrain\u001b[39m.\u001b[39mget_global_step(g)\n\u001b[0;32m   1217\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[0;32m   1218\u001b[0m                                        hooks, global_step_tensor,\n\u001b[0;32m   1219\u001b[0m                                        saving_listeners)\n",
      "File \u001b[1;32mc:\\Otro\\Anaconda\\envs\\GPU_AMI\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:1174\u001b[0m, in \u001b[0;36mEstimator._call_model_fn\u001b[1;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[0;32m   1171\u001b[0m   kwargs[\u001b[39m'\u001b[39m\u001b[39mconfig\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m config\n\u001b[0;32m   1173\u001b[0m logging\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mCalling model_fn.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m-> 1174\u001b[0m model_fn_results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model_fn(features\u001b[39m=\u001b[39mfeatures, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1175\u001b[0m logging\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mDone calling model_fn.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m   1177\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(model_fn_results, model_fn_lib\u001b[39m.\u001b[39mEstimatorSpec):\n",
      "File \u001b[1;32mc:\\Otro\\Anaconda\\envs\\GPU_AMI\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\dnn.py:1159\u001b[0m, in \u001b[0;36mDNNRegressorV2.__init__.<locals>._model_fn\u001b[1;34m(features, labels, mode, config)\u001b[0m\n\u001b[0;32m   1157\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_model_fn\u001b[39m(features, labels, mode, config):\n\u001b[0;32m   1158\u001b[0m   \u001b[39m\"\"\"Call the defined shared dnn_model_fn_v2.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1159\u001b[0m   \u001b[39mreturn\u001b[39;00m dnn_model_fn_v2(\n\u001b[0;32m   1160\u001b[0m       features\u001b[39m=\u001b[39;49mfeatures,\n\u001b[0;32m   1161\u001b[0m       labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   1162\u001b[0m       mode\u001b[39m=\u001b[39;49mmode,\n\u001b[0;32m   1163\u001b[0m       head\u001b[39m=\u001b[39;49mhead,\n\u001b[0;32m   1164\u001b[0m       hidden_units\u001b[39m=\u001b[39;49mhidden_units,\n\u001b[0;32m   1165\u001b[0m       feature_columns\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(feature_columns \u001b[39mor\u001b[39;49;00m []),\n\u001b[0;32m   1166\u001b[0m       optimizer\u001b[39m=\u001b[39;49moptimizer,\n\u001b[0;32m   1167\u001b[0m       activation_fn\u001b[39m=\u001b[39;49mactivation_fn,\n\u001b[0;32m   1168\u001b[0m       dropout\u001b[39m=\u001b[39;49mdropout,\n\u001b[0;32m   1169\u001b[0m       config\u001b[39m=\u001b[39;49mconfig,\n\u001b[0;32m   1170\u001b[0m       batch_norm\u001b[39m=\u001b[39;49mbatch_norm)\n",
      "File \u001b[1;32mc:\\Otro\\Anaconda\\envs\\GPU_AMI\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\dnn.py:556\u001b[0m, in \u001b[0;36mdnn_model_fn_v2\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    552\u001b[0m _validate_features(features)\n\u001b[0;32m    554\u001b[0m \u001b[39mdel\u001b[39;00m config\n\u001b[1;32m--> 556\u001b[0m logits, trainable_variables, update_ops \u001b[39m=\u001b[39m _dnn_model_fn_builder_v2(\n\u001b[0;32m    557\u001b[0m     units\u001b[39m=\u001b[39;49mhead\u001b[39m.\u001b[39;49mlogits_dimension,\n\u001b[0;32m    558\u001b[0m     hidden_units\u001b[39m=\u001b[39;49mhidden_units,\n\u001b[0;32m    559\u001b[0m     feature_columns\u001b[39m=\u001b[39;49mfeature_columns,\n\u001b[0;32m    560\u001b[0m     activation_fn\u001b[39m=\u001b[39;49mactivation_fn,\n\u001b[0;32m    561\u001b[0m     dropout\u001b[39m=\u001b[39;49mdropout,\n\u001b[0;32m    562\u001b[0m     batch_norm\u001b[39m=\u001b[39;49mbatch_norm,\n\u001b[0;32m    563\u001b[0m     features\u001b[39m=\u001b[39;49mfeatures,\n\u001b[0;32m    564\u001b[0m     mode\u001b[39m=\u001b[39;49mmode)\n\u001b[0;32m    566\u001b[0m \u001b[39m# In TRAIN mode, create optimizer and assign global_step variable to\u001b[39;00m\n\u001b[0;32m    567\u001b[0m \u001b[39m# optimizer.iterations to make global_step increased correctly, as Hooks\u001b[39;00m\n\u001b[0;32m    568\u001b[0m \u001b[39m# relies on global step as step counter.\u001b[39;00m\n\u001b[0;32m    569\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m ModeKeys\u001b[39m.\u001b[39mTRAIN:\n",
      "File \u001b[1;32mc:\\Otro\\Anaconda\\envs\\GPU_AMI\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\dnn.py:500\u001b[0m, in \u001b[0;36m_dnn_model_fn_builder_v2\u001b[1;34m(units, hidden_units, feature_columns, activation_fn, dropout, batch_norm, features, mode)\u001b[0m\n\u001b[0;32m    490\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39munits must be an int.  Given type: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    491\u001b[0m       \u001b[39mtype\u001b[39m(units)))\n\u001b[0;32m    492\u001b[0m dnn_model \u001b[39m=\u001b[39m _DNNModelV2(\n\u001b[0;32m    493\u001b[0m     units,\n\u001b[0;32m    494\u001b[0m     hidden_units,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    498\u001b[0m     batch_norm,\n\u001b[0;32m    499\u001b[0m     name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdnn\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 500\u001b[0m logits \u001b[39m=\u001b[39m dnn_model(features, mode)\n\u001b[0;32m    501\u001b[0m trainable_variables \u001b[39m=\u001b[39m dnn_model\u001b[39m.\u001b[39mtrainable_variables\n\u001b[0;32m    502\u001b[0m update_ops \u001b[39m=\u001b[39m dnn_model\u001b[39m.\u001b[39mupdates\n",
      "File \u001b[1;32mc:\\Otro\\Anaconda\\envs\\GPU_AMI\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Otro\\Anaconda\\envs\\GPU_AMI\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\dnn.py:346\u001b[0m, in \u001b[0;36m_DNNModelV2.call\u001b[1;34m(self, features, mode)\u001b[0m\n\u001b[0;32m    344\u001b[0m is_training \u001b[39m=\u001b[39m mode \u001b[39m==\u001b[39m ModeKeys\u001b[39m.\u001b[39mTRAIN\n\u001b[0;32m    345\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 346\u001b[0m   net \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_layer(features, training\u001b[39m=\u001b[39mis_training)\n\u001b[0;32m    347\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m   net \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_layer(features)\n",
      "\u001b[1;31mValueError\u001b[0m: Feature image is not in features dictionary."
     ]
    }
   ],
   "source": [
    "size = tf.feature_column.numeric_column(\"size\")\n",
    "\n",
    "rooms = tf.feature_column.categorical_column_with_vocabulary_list(\"rooms\", ['1','2','3','4','5'])\n",
    "\n",
    "features_list = [size, rooms]\n",
    "\n",
    "features_list = [tf.feature_column.numeric_column('image', shape=(784,))]\n",
    "\n",
    "def input_fn():\n",
    "    features = {'size' : [1340, 1690, 2720],\n",
    "                'rooms' : [1,3,4]}\n",
    "    labels = [221900, 538000, 180000]\n",
    "\n",
    "    return features, labels\n",
    "\n",
    "#Define a deep NN regression\n",
    "model0 = tf.estimator.DNNRegressor(feature_columns = features_list, hidden_units=[10,6,6,3])\n",
    "\n",
    "#Train the regression model\n",
    "model0.train(input_fn, steps=20)\n",
    "\n",
    "\n",
    "#FOR CLASSIFICATION\n",
    "\n",
    "#Define a deep NN classifier\n",
    "model0 = tf.estimator.DNNClassifier(feature_columns = features_list, hidden_units=[32,16,8], n_classes=4)\n",
    "\n",
    "#Train the classifier\n",
    "model0.train(input_fn, steps=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducing Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fully integrrated into TensorFlow 2\n",
    "- Can use TF for low level features\n",
    "- NN good for unstructured data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Going Deeper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving your model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Model Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Deep Learning with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('GPU_AMI')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e1967b0f77bf082c22faa1807af039d6ee4e7cb97c96c5b82449ce23140f1766"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
